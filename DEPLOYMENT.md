# ğŸš€ Sentinel Deployment Guide - Week 1 Complete

## âœ… What's Been Built

### ğŸ“¦ Deliverables Completed

**âœ“ Engineer #1: Core Agent Architecture**
- OpenClaw Sentinel profile initialized (`~/.openclaw-sentinel/`)
- Configuration file created (`config/sentinel.yaml`)
- Heartbeat orchestration script (`scripts/run_sentinel.sh`)
- Systemd service definition

**âœ“ Engineer #2: Computer Vision Pipeline**
- Vision skill with YOLO detection (`skills/vision_skill.py`)
- Temporal filtering (3-frame anti-flicker)
- ISO 8601 timestamp injection
- 7-day automatic rotation
- Target: <500ms capture+inference

**âœ“ Engineer #3: LLM & Memory**
- Conversation skill with safety protocol (`skills/conversation_skill.py`)
- SQLite database with vector embeddings
- 3-question workflow state machine
- Ollama qwen2.5:3b integration

**âœ“ Engineer #4: Security & DevOps**
- Docker multi-stage build (`Dockerfile`)
- Docker Compose with resource limits (`docker-compose.yml`)
- Systemd service with AppArmor hints
- Environment-based secret management
- Installation script (`scripts/install.sh`)

**âœ“ Engineer #5: Workflows & Testing**
- Safety protocols YAML (`workflows/safety_protocols.yaml`)
- Integration test suite (`scripts/test_sentinel.sh`)
- Graceful degradation rules
- Performance benchmarks

---

## ğŸ¯ Quick Deployment (5 Minutes)

### Step 1: Install Dependencies

```bash
cd ~/sentinel
chmod +x scripts/install.sh
./scripts/install.sh
```

**This will:**
- âœ“ Install Python 3.11 dependencies
- âœ“ Download Ollama and pull `qwen2.5:3b`
- âœ“ Download YOLOv8-nano ONNX model
- âœ“ Create virtual environment
- âœ“ Set up systemd service

### Step 2: Configure Secrets

```bash
# Add to ~/.bashrc or ~/.profile
export TELEGRAM_BOT_TOKEN="your_bot_token_here"
export ANTHROPIC_API_KEY="sk-ant-..."  # Optional

# Reload
source ~/.bashrc
```

### Step 3: Run Tests

```bash
./scripts/test_sentinel.sh
```

**Expected Output:**
```
âœ“ Vision skill executed successfully
âœ“ Conversation skill executed successfully
âœ“ Ollama is running
âœ“ qwen2.5:3b model available
âœ“ YOLO model found
âœ“ CUDA available (MX130 detected)
âœ“ Capture directory exists
âœ“ SQLite database accessible
âœ“ Configuration is valid YAML
```

### Step 4: Start Sentinel

```bash
# Option A: Systemd (recommended)
sudo systemctl enable sentinel
sudo systemctl start sentinel
journalctl -u sentinel -f

# Option B: Manual foreground
source ~/sentinel/.venv/bin/activate
./scripts/run_sentinel.sh

# Option C: Docker
docker-compose up -d
docker-compose logs -f sentinel
```

---

## ğŸ“Š Verification Checklist

After deployment, verify:

- [ ] **Ollama Running**: `curl http://localhost:11434/api/tags`
- [ ] **OpenClaw Initialized**: `ls ~/.openclaw-sentinel/`
- [ ] **Camera Accessible**: `ls /dev/video0`
- [ ] **GPU Detected**: `nvidia-smi` shows MX130
- [ ] **Models Downloaded**: `ls ~/sentinel/models/yolov8n.onnx`
- [ ] **Captures Directory**: `ls ~/sentinel_captures/`
- [ ] **Logs Created**: `tail ~/sentinel/logs/sentinel.log`

---

## ğŸ” Understanding the Flow

### 1. Heartbeat Loop (Every 60 seconds)

```bash
# In run_sentinel.sh
while true; do
    # Execute vision skill
    python3 skills/vision_skill.py
    # Returns: {"person_present": bool, "confidence": float}

    if person_present == true; then
        # Trigger conversation skill
        python3 skills/conversation_skill.py
    fi

    sleep 60
done
```

### 2. Vision Skill Pipeline

```
Camera â†’ Capture (1280x720)
   â†“
YOLOv8-nano ONNX (MX130 GPU)
   â†“
Person Detection (class 0)
   â†“
Temporal Filter (3 consecutive frames >0.85 confidence)
   â†“
Return JSON: {"person_present": bool}
```

### 3. Conversation Skill Workflow

```
Trigger (person_present=true)
   â†“
Q1: "What task are you performing?"
   â†“
[Wait for Telegram reply]
   â†“
Q2: "Are safety protocols confirmed?"
   â†“
[Wait for Telegram reply]
   â†“
Q3: "Do you require tool access?" (conditional)
   â†“
Store to SQLite + Vector Embeddings
   â†“
Return to monitoring
```

---

## ğŸ› Common Issues & Solutions

### Issue: "Camera failed to open"

```bash
# Check device exists
ls -l /dev/video0

# Add user to video group
sudo usermod -aG video $USER

# Reboot
sudo reboot
```

### Issue: "CUDA not available"

```bash
# Check NVIDIA drivers
nvidia-smi

# If not installed (for MX130)
sudo apt install nvidia-driver-470
sudo reboot

# Verify CUDA
python3 -c "import torch; print(torch.cuda.is_available())"
```

### Issue: "Ollama connection failed"

```bash
# Start Ollama manually
ollama serve &

# Or enable systemd service
sudo systemctl enable ollama
sudo systemctl start ollama

# Verify
curl http://localhost:11434/api/tags
```

### Issue: "YOLO model not found"

```bash
# Re-run model download section
cd ~/sentinel/models
python3 << EOF
from ultralytics import YOLO
model = YOLO("yolov8n.pt")
model.export(format="onnx", dynamic=False)
EOF
```

### Issue: "Out of memory"

```bash
# Check usage
free -h

# Option 1: Use lighter model
ollama pull phi3:mini
# Update config/sentinel.yaml: model: "phi3:mini"

# Option 2: Increase swap
sudo fallocate -l 4G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
```

---

## ğŸ“ˆ Monitoring & Metrics

### Real-Time Monitoring

```bash
# System resources
watch -n 1 'free -h; nvidia-smi | grep MX130'

# Capture rate
watch -n 5 'ls ~/sentinel_captures/$(date +%Y-%m-%d) | wc -l'

# Database size
watch -n 60 'du -sh ~/.openclaw-sentinel/sentinel_memory.db'

# Service logs
journalctl -u sentinel -f --since "10 minutes ago"
```

### Performance Metrics

```bash
# Vision skill latency
time python3 ~/sentinel/skills/vision_skill.py

# Conversation skill latency
echo '{"session_id":"test","trigger_conversation":true}' | \
  time python3 ~/sentinel/skills/conversation_skill.py

# Ollama response time
time ollama run qwen2.5:3b "Hello"
```

### Expected Benchmarks (HP Pavilion x360)

| Metric | Target | Command |
|--------|--------|---------|
| OpenClaw Memory | <10MB | `ps -o rss= -p $(pgrep openclaw)` |
| Vision Latency | <500ms | `time python3 skills/vision_skill.py` |
| YOLO Inference | <50ms | Check logs for "inference_time" |
| Ollama Response | <2s | `time ollama run qwen2.5:3b "test"` |

---

## ğŸ” Security Hardening (Production)

### 1. Restrict File Permissions

```bash
chmod 600 ~/.openclaw-sentinel/openclaw.json
chmod 700 ~/sentinel/skills/
chmod 755 ~/sentinel_captures/
```

### 2. Enable AppArmor

```bash
# Create profile (Engineer #4 deliverable)
sudo tee /etc/apparmor.d/sentinel << 'EOF'
/home/*/sentinel/scripts/run_sentinel.sh {
  /home/*/sentinel/** r,
  /home/*/sentinel_captures/** rw,
  /home/*/.openclaw-sentinel/** rw,
  /usr/bin/python3* rix,
  deny /etc/shadow r,
}
EOF

sudo apparmor_parser -r /etc/apparmor.d/sentinel
sudo aa-enforce /home/$USER/sentinel/scripts/run_sentinel.sh
```

### 3. Firewall Rules (No Internet Mode)

```bash
# Block all egress except localhost
sudo ufw enable
sudo ufw default deny outgoing
sudo ufw allow out to 127.0.0.1
sudo ufw allow out 443/tcp  # For Telegram (if needed)
```

### 4. Audit AI-Generated Code

```bash
# Check for unexpected network calls
strings ~/.npm-global/lib/node_modules/openclaw/dist/*.js | \
  grep -E 'https?://' | \
  grep -v 'localhost\|127.0.0.1'
```

---

## ğŸ“… Week 2 & 3 Roadmap

### Week 2: Intelligence & Conversation
- [ ] Complete Telegram bot webhook integration
- [ ] Implement conversation state persistence across reboots
- [ ] Add vector search for context retrieval
- [ ] Test 3-question workflow end-to-end
- [ ] Tune Ollama temperature for safety responses

### Week 3: Resilience & Polish
- [ ] Cloud fallback to Anthropic Claude
- [ ] 48-hour continuous stress test
- [ ] False positive rate tuning (<1%)
- [ ] Memory leak detection and fixes
- [ ] Production deployment documentation

---

## ğŸ“Š Current Status

### âœ… Completed (Week 1)
- Core OpenClaw architecture
- Vision pipeline with YOLO
- Conversation skill skeleton
- Security configuration
- Docker deployment
- Installation scripts
- Testing suite

### ğŸ”„ In Progress (Week 2)
- Telegram webhook handlers
- Ollama integration refinement
- SQLite vector search optimization

### ğŸ“‹ Planned (Week 3)
- Cloud fallback implementation
- Stress testing (48 hours)
- Performance optimization
- Production hardening

---

## ğŸ¯ Next Steps

1. **Run Installation**
   ```bash
   cd ~/sentinel
   ./scripts/install.sh
   ```

2. **Execute Tests**
   ```bash
   ./scripts/test_sentinel.sh
   ```

3. **Start Service**
   ```bash
   sudo systemctl start sentinel
   ```

4. **Monitor for 24 Hours**
   ```bash
   journalctl -u sentinel -f
   ```

5. **Review Captures**
   ```bash
   ls -lh ~/sentinel_captures/$(date +%Y-%m-%d)/
   ```

---

## ğŸ“ Support

- **Logs**: `journalctl -u sentinel -f`
- **Config**: `~/sentinel/config/sentinel.yaml`
- **Database**: `~/.openclaw-sentinel/sentinel_memory.db`
- **Captures**: `~/sentinel_captures/`

---

**Deployment Status**: âœ… Week 1 Complete
**Next Milestone**: Week 2 - Intelligence & Conversation
**Target Hardware**: HP Pavilion x360 (i7-8550U, 12GB RAM, MX130)

**ğŸ›¡ï¸ Sentinel is ready for deployment.**
